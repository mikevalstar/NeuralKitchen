import { openai } from "@ai-sdk/openai";
import { embed, generateText } from "ai";
import { Prompts } from "../data/prompts";
import { Settings } from "../data/settings";

// Lazy-initialized OpenAI client for AI SDK
let openaiClient: typeof openai | null = null;

function getOpenAIClient() {
  if (!openaiClient) {
    const apiKey = Settings.get("OPENAI_API_KEY");
    if (!apiKey) {
      throw new Error("OPENAI_API_KEY setting is not configured");
    }
    openaiClient = openai;
  }
  return openaiClient;
}

export namespace AIService {
  /**
   * Simple token estimation - approximately 4 characters per token for English text
   * This is a rough approximation since proper tokenization requires the specific model's tokenizer
   */
  function estimateTokens(text: string): number {
    return Math.ceil(text.length / 4);
  }

  /**
   * Truncate text to approximately the specified number of tokens
   */
  function truncateToTokens(text: string, maxTokens: number): string {
    const estimatedTokens = estimateTokens(text);

    if (estimatedTokens <= maxTokens) {
      return text;
    }

    // Estimate how many characters we need to keep
    const targetLength = Math.floor(maxTokens * 4);

    // Truncate and try to break at a word boundary if possible
    let truncated = text.slice(0, targetLength);
    const lastSpaceIndex = truncated.lastIndexOf(" ");

    // If we can find a space within the last 100 characters, break there
    if (lastSpaceIndex > targetLength - 100) {
      truncated = truncated.slice(0, lastSpaceIndex);
    }

    return truncated;
  }

  /**
   * Generate embeddings for text using AI SDK
   * Using text-embedding-3-small for cost efficiency
   */
  export async function generateEmbedding(text: string): Promise<number[]> {
    try {
      const client = getOpenAIClient();

      // Truncate text to approximately 6000 tokens to stay well within the 8192 token limit
      const truncatedText = truncateToTokens(text, 6000);

      const { embedding } = await embed({
        model: client.embedding("text-embedding-3-small"),
        value: truncatedText,
      });

      if (!embedding) {
        throw new Error("No embedding generated by AI service");
      }

      return embedding;
    } catch (error) {
      console.error("Error generating embedding:", error);
      throw new Error(`Failed to generate embedding: ${error instanceof Error ? error.message : "Unknown error"}`);
    }
  }

  /**
   * Summarize a recipe document using AI SDK
   */
  export async function summarizeRecipe(title: string, content: string): Promise<string> {
    try {
      const client = getOpenAIClient();

      // Get prompts from database with fallback to constants
      const [systemPrompt, userPromptTemplate] = await Promise.all([
        Prompts.getByKey("RECIPE_SUMMARY_SYSTEM"),
        Prompts.getByKey("RECIPE_SUMMARY_USER"),
      ]);

      // Replace placeholders in user prompt
      const userPrompt = userPromptTemplate.replace("{title}", title).replace("{content}", content);

      const { text } = await generateText({
        model: client("gpt-4o-mini"),
        system: systemPrompt,
        prompt: userPrompt,
        maxOutputTokens: 2000,
        temperature: 0.3,
      });

      if (!text) {
        throw new Error("No summary generated by AI service");
      }

      return text.trim();
    } catch (error) {
      console.error("Error calling AI service:", error);
      throw new Error(`Failed to summarize recipe: ${error instanceof Error ? error.message : "Unknown error"}`);
    }
  }

  /**
   * Generate text using AI SDK with custom parameters
   */
  export async function generateTextCompletion(
    prompt: string,
    options?: {
      system?: string;
      model?: string;
      maxTokens?: number;
      temperature?: number;
    },
  ): Promise<string> {
    try {
      const client = getOpenAIClient();

      const { text } = await generateText({
        model: client(options?.model || "gpt-4o-mini"),
        system: options?.system,
        prompt,
        maxOutputTokens: options?.maxTokens || 1000,
        temperature: options?.temperature || 0.7,
      });

      if (!text) {
        throw new Error("No text generated by AI service");
      }

      return text.trim();
    } catch (error) {
      console.error("Error generating text completion:", error);
      throw new Error(`Failed to generate text: ${error instanceof Error ? error.message : "Unknown error"}`);
    }
  }
}
