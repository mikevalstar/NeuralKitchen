import OpenAI from "openai";

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export namespace OpenAIService {
  /**
   * Summarize a recipe document using GPT-4o-mini
   */
  export async function summarizeRecipe(title: string, content: string): Promise<string> {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error("OPENAI_API_KEY environment variable is not set");
    }

    try {
      const response = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: `You are an AI assistant that creates concise summaries of code development recipes/tutorials and code documentation. Your summaries should:

1. Be 5 paragraphs maximum
2. It should be written in markdown format
3. Should be written in the same language, tone and style as the original content
4. Focus on the main purpose and key outcome
5. Mention the primary technology/framework if relevant  
6. Be written so that it has all keywords and phrases that would be used to search for this recipe
7. Avoid implementation details - focus on the "what" and "why"

Keep the summary professional and actionable.`,
          },
          {
            role: "user",
            content: `Please summarize this development recipe:

Title: ${title}

Content:
${content}`,
          },
        ],
        max_tokens: 2000,
        temperature: 0.3,
      });

      const summary = response.choices[0]?.message?.content?.trim();

      if (!summary) {
        throw new Error("No summary generated by OpenAI");
      }

      return summary;
    } catch (error) {
      console.error("Error calling OpenAI API:", error);
      throw new Error(`Failed to summarize recipe: ${error instanceof Error ? error.message : "Unknown error"}`);
    }
  }

  /**
   * Simple token estimation - approximately 4 characters per token for English text
   * This is a rough approximation since proper tokenization requires the specific model's tokenizer
   */
  function estimateTokens(text: string): number {
    return Math.ceil(text.length / 4);
  }

  /**
   * Truncate text to approximately the specified number of tokens
   */
  function truncateToTokens(text: string, maxTokens: number): string {
    const estimatedTokens = estimateTokens(text);

    if (estimatedTokens <= maxTokens) {
      return text;
    }

    // Estimate how many characters we need to keep
    const targetLength = Math.floor(maxTokens * 4);

    // Truncate and try to break at a word boundary if possible
    let truncated = text.slice(0, targetLength);
    const lastSpaceIndex = truncated.lastIndexOf(" ");

    // If we can find a space within the last 100 characters, break there
    if (lastSpaceIndex > targetLength - 100) {
      truncated = truncated.slice(0, lastSpaceIndex);
    }

    return truncated;
  }

  /**
   * Generate embeddings for a recipe document (for future vector search)
   * Using text-embedding-3-small for cost efficiency
   */
  export async function generateEmbedding(text: string): Promise<number[]> {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error("OPENAI_API_KEY environment variable is not set");
    }

    try {
      // Truncate text to approximately 6000 tokens to stay well within the 8192 token limit
      const truncatedText = truncateToTokens(text, 6000);

      const response = await openai.embeddings.create({
        model: "text-embedding-3-small",
        input: truncatedText,
      });

      const embedding = response.data[0]?.embedding;

      if (!embedding) {
        throw new Error("No embedding generated by OpenAI");
      }

      return embedding;
    } catch (error) {
      console.error("Error generating embedding:", error);
      throw new Error(`Failed to generate embedding: ${error instanceof Error ? error.message : "Unknown error"}`);
    }
  }
}
